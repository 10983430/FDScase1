{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " --------------------------------------------------------------------------------------\n",
    "# Preprocessing\n",
    "### This file imports the twitter datafile and :\n",
    "#####  - Creates a pandas dataframe from the data\n",
    "#####  - Creates a new column with only the text of the tweet, excluding mentions and hyperlinks\n",
    "#####  - Drops every tweet that does not contain any text, to remove spam links and mentions\n",
    "\n",
    "### This result is then saved to an .xlsx file\n",
    "--------------------------------------------------------------------------------------\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Verander dit naar je filelocation en dan werkt alles als het goed is\n",
    "filelocation = \"geotagged_tweets_20160812-0912.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import json\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data uitladen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have gathered: 657307 tweets.\n",
      "dict_keys(['created_at', 'id', 'id_str', 'text', 'source', 'truncated', 'in_reply_to_status_id', 'in_reply_to_status_id_str', 'in_reply_to_user_id', 'in_reply_to_user_id_str', 'in_reply_to_screen_name', 'user', 'geo', 'coordinates', 'place', 'contributors', 'is_quote_status', 'retweet_count', 'favorite_count', 'entities', 'extended_entities', 'favorited', 'retweeted', 'possibly_sensitive', 'filter_level', 'lang', 'timestamp_ms'])\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tweets_data = []\n",
    "tweets_file = open(filelocation, \"r\")\n",
    "\n",
    "i = 0    \n",
    "for line in tweets_file:\n",
    "    i += 1\n",
    "    #Comment de volgende twee regels uit als je alle tweets wilt\n",
    "    #for i in range(2000):    \n",
    "        #if i%100000 == 0:\n",
    "            #print(i)\n",
    "    try:\n",
    "        tweet = json.loads(line)\n",
    "        tweets_data.append(tweet)\n",
    "    except Exception as e:\n",
    "        print (e)\n",
    "        continue\n",
    "\n",
    "       \n",
    "print ('We have gathered:',len(tweets_data), 'tweets.')\n",
    "#print (\"Information contained in a single tweet: \\n\")\n",
    "pprint(tweets_data[0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets = pd.DataFrame.from_dict(tweets_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Delete hyperlinks\n",
    "#tweets['text'] = tweets['text'].replace(r'http\\S+', '', regex=True).replace(r'www\\S+', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_string(row):\n",
    "    # remove http and www links from string\n",
    "    rem_hl = re.sub(r'(http\\S+) | (www\\S+) | (https\\S+)', '', row['text'])\n",
    "    \n",
    "    # remove @.. from string\n",
    "    rem_at_hl = re.sub(r'@(\\w+) |@(\\w+)', '', rem_hl)\n",
    "    \n",
    "    # remove hashtags #.. from string\n",
    "    rem_hash_at_hl = re.sub(r'#(\\w+) |@(\\w+)', '', rem_at_hl)\n",
    "\n",
    "    rem_inter = re.sub(r'[^\\w\\s]','', rem_hash_at_hl)\n",
    "    \n",
    "    # remove multiple spaces\n",
    "    rem_space = re.sub(' +',' ',rem_inter)\n",
    "    #print (re.search('[a-zA-Z]', rem_space))\n",
    "    if (re.search('[a-zA-Z]', rem_space) == None):\n",
    "        return(\"emptyStringRetured\")\n",
    "    else:\n",
    "        return (rem_space)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets['CleanText'] = tweets.apply(lambda row: clean_string(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleaned = tweets[tweets['CleanText'].str.contains(\"emptyStringRetured\") == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "610335"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleaned.to_json('twitter_geotagged_clean.json', orient='records', lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
